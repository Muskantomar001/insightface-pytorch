{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prior_box",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo_QTqpjJP6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#retinaface\n",
        "#layers\n",
        "#functions\n",
        "#prior_box.py\n",
        "\n",
        "from itertools import product as product\n",
        "from math import ceil\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "class PriorBox(object):\n",
        "    def __init__(self, cfg, image_size=None, phase='train'):\n",
        "        super(PriorBox, self).__init__()\n",
        "        self.min_sizes = cfg['min_sizes']\n",
        "        self.steps = cfg['steps']\n",
        "        self.clip = cfg['clip']\n",
        "        self.image_size = image_size\n",
        "        self.feature_maps = [[ceil(self.image_size[0] / step), ceil(self.image_size[1] / step)] for step in self.steps]\n",
        "        self.name = \"s\"\n",
        "\n",
        "    def forward(self):\n",
        "        anchors = []\n",
        "        for k, f in enumerate(self.feature_maps):\n",
        "            min_sizes = self.min_sizes[k]\n",
        "            for i, j in product(range(f[0]), range(f[1])):\n",
        "                for min_size in min_sizes:\n",
        "                    s_kx = min_size / self.image_size[1]\n",
        "                    s_ky = min_size / self.image_size[0]\n",
        "                    dense_cx = [x * self.steps[k] / self.image_size[1] for x in [j + 0.5]]\n",
        "                    dense_cy = [y * self.steps[k] / self.image_size[0] for y in [i + 0.5]]\n",
        "                    for cy, cx in product(dense_cy, dense_cx):\n",
        "                        anchors += [cx, cy, s_kx, s_ky]\n",
        "\n",
        "        # back to torch land\n",
        "        output = torch.Tensor(anchors).view(-1, 4)\n",
        "        if self.clip:\n",
        "            output.clamp_(max=1, min=0)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}