{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.py",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfc5An0rKCMW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "4623e6a5-036c-4b36-8840-70e7cf76c7bb"
      },
      "source": [
        "#train.py\n",
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from config import device, grad_clip, print_freq\n",
        "from data_gen import ArcFaceDataset\n",
        "from focal_loss import FocalLoss\n",
        "from lfw_eval import lfw_test\n",
        "from models1 import resnet18, resnet34, resnet50, resnet101, resnet152, ArcMarginModel\n",
        "from optimizer import InsightFaceOptimizer\n",
        "from utils import parse_args, save_checkpoint, AverageMeter, accuracy, get_logger\n",
        "\n",
        "\n",
        "def full_log(epoch):\n",
        "    full_log_dir = 'data/full_log'\n",
        "    if not os.path.isdir(full_log_dir):\n",
        "        os.mkdir(full_log_dir)\n",
        "    filename = 'angles_{}.txt'.format(epoch)\n",
        "    dst_file = os.path.join(full_log_dir, filename)\n",
        "    src_file = 'data/angles.txt'\n",
        "    copyfile(src_file, dst_file)\n",
        "\n",
        "\n",
        "def train_net(args):\n",
        "    torch.manual_seed(7)\n",
        "    np.random.seed(7)\n",
        "    checkpoint = args.checkpoint\n",
        "    start_epoch = 0\n",
        "    best_acc = float('-inf')\n",
        "    writer = SummaryWriter()\n",
        "    epochs_since_improvement = 0\n",
        "\n",
        "    # Initialize / load checkpoint\n",
        "    if checkpoint is None:\n",
        "        if args.network == 'r18':\n",
        "            model = resnet18(args)\n",
        "        elif args.network == 'r34':\n",
        "            model = resnet34(args)\n",
        "        elif args.network == 'r50':\n",
        "            model = resnet50(args)\n",
        "        elif args.network == 'r101':\n",
        "            model = resnet101(args)\n",
        "        elif args.network == 'r152':\n",
        "            model = resnet152(args)\n",
        "        else:\n",
        "            raise TypeError('network {} is not supported.'.format(args.network))\n",
        "\n",
        "        # print(model)\n",
        "        model = nn.DataParallel(model)\n",
        "        metric_fc = ArcMarginModel(args)\n",
        "        metric_fc = nn.DataParallel(metric_fc)\n",
        "\n",
        "        if args.optimizer == 'sgd':\n",
        "            optimizer = InsightFaceOptimizer(\n",
        "                torch.optim.SGD([{'params': model.parameters()}, {'params': metric_fc.parameters()}],\n",
        "                                lr=args.lr, momentum=args.mom, weight_decay=args.weight_decay))\n",
        "        else:\n",
        "            optimizer = InsightFaceOptimizer(\n",
        "                torch.optim.Adam([{'params': model.parameters()}, {'params': metric_fc.parameters()}],\n",
        "                                 lr=args.lr, weight_decay=args.weight_decay))\n",
        "\n",
        "    else:\n",
        "        checkpoint = torch.load(checkpoint)\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
        "        model = checkpoint['model']\n",
        "        metric_fc = checkpoint['metric_fc']\n",
        "        optimizer = checkpoint['optimizer']\n",
        "\n",
        "    logger = get_logger()\n",
        "\n",
        "    # Move to GPU, if available\n",
        "    model = model.to(device)\n",
        "    metric_fc = metric_fc.to(device)\n",
        "\n",
        "    # Loss function\n",
        "    if args.focal_loss:\n",
        "        criterion = FocalLoss(gamma=args.gamma).to(device)\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    # Custom dataloaders\n",
        "    train_dataset = ArcFaceDataset('train')\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "    # Epochs\n",
        "    for epoch in range(start_epoch, args.end_epoch):\n",
        "        # One epoch's training\n",
        "        train_loss, train_acc = train(train_loader=train_loader,\n",
        "                                      model=model,\n",
        "                                      metric_fc=metric_fc,\n",
        "                                      criterion=criterion,\n",
        "                                      optimizer=optimizer,\n",
        "                                      epoch=epoch,\n",
        "                                      logger=logger)\n",
        "\n",
        "        writer.add_scalar('model/train_loss', train_loss, epoch)\n",
        "        writer.add_scalar('model/train_acc', train_acc, epoch)\n",
        "\n",
        "        logger.info('Learning rate={}, step number={}\\n'.format(optimizer.lr, optimizer.step_num))\n",
        "\n",
        "        # One epoch's validation\n",
        "        lfw_acc, threshold = lfw_test(model)\n",
        "        writer.add_scalar('model/valid_acc', lfw_acc, epoch)\n",
        "        writer.add_scalar('model/valid_thres', threshold, epoch)\n",
        "\n",
        "        # Check if there was an improvement\n",
        "        is_best = lfw_acc > best_acc\n",
        "        best_acc = max(lfw_acc, best_acc)\n",
        "        if not is_best:\n",
        "            epochs_since_improvement += 1\n",
        "            print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
        "        else:\n",
        "            epochs_since_improvement = 0\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_checkpoint(epoch, epochs_since_improvement, model, metric_fc, optimizer, best_acc, is_best)\n",
        "\n",
        "\n",
        "def train(train_loader, model, metric_fc, criterion, optimizer, epoch, logger):\n",
        "    model.train()  # train mode (dropout and batchnorm is used)\n",
        "    metric_fc.train()\n",
        "\n",
        "    losses = AverageMeter()\n",
        "    top5_accs = AverageMeter()\n",
        "\n",
        "    # Batches\n",
        "    for i, (img, label) in enumerate(train_loader):\n",
        "        # Move to GPU, if available\n",
        "        img = img.to(device)\n",
        "        label = label.to(device)  # [N, 1]\n",
        "\n",
        "        # Forward prop.\n",
        "        feature = model(img)  # embedding => [N, 512]\n",
        "        output = metric_fc(feature, label)  # class_id_out => [N, 93431]\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, label)\n",
        "\n",
        "        # Back prop.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        optimizer.clip_gradient(grad_clip)\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Keep track of metrics\n",
        "        losses.update(loss.item())\n",
        "        top5_accuracy = accuracy(output, label, 5)\n",
        "        top5_accs.update(top5_accuracy)\n",
        "\n",
        "        # Print status\n",
        "        if i % print_freq == 0:\n",
        "            logger.info('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                        'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                        'Top5 Accuracy {top5_accs.val:.3f} ({top5_accs.avg:.3f})'.format(epoch, i, len(train_loader),\n",
        "                                                                                         loss=losses,\n",
        "                                                                                         top5_accs=top5_accs))\n",
        "\n",
        "    return losses.avg, top5_accs.avg\n",
        "\n",
        "\n",
        "def main():\n",
        "    global args\n",
        "    args = parse_args()\n",
        "    train_net(args)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/content/drive/My Drive/DLDatasets/models1.py\"\u001b[0;36m, line \u001b[0;32m380\u001b[0m\n\u001b[0;31m    !pip install torch-scope\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5xw189fb8yP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/models1.py\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwnJfzeUaUes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1a1f946b-83b7-4d17-a138-6dd4c7bca972"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/DLDatasets\")\n",
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "align_faces.py\t first_stage.py    lfw_dataset.zip    __pycache__\n",
            "box_utils1.py\t focal_loss.ipynb  lfw_eval.py\t      py_cpu_nms.py\n",
            "box_utils.py\t focal_loss.py\t   loader.py\t      retinaface.py\n",
            "config1.py\t image_aug.ipynb   models1.ipynb      train.py\n",
            "config.py\t image_aug.py\t   models1.py\t      utils.py\n",
            "data\t\t _init_.py\t   models.py\t      visualization_utils.py\n",
            "data_augment.py  _init.py\t   msceleb.zip\t      wider_face.py\n",
            "data_gen.ipynb\t insightface\t   multibox_loss1.py\n",
            "data_gen.py\t insightface1\t   net.py\n",
            "detector.py\t InsightFace-v2    prior_box.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UmOYVPeafQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/lfw_eval.py\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf1Y1pjEbB2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/focal_loss.py\" ."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}