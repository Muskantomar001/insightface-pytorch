{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5MqFwI06e8",
        "colab_type": "code",
        "outputId": "215a1afa-a9ad-48c5-ab27-02d7fde8d300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "#utils.py\n",
        "import argparse\n",
        "import logging\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from align_faces import get_reference_facial_points, warp_and_crop_face\n",
        "from config import image_h, image_w\n",
        "from detector import detect_faces\n",
        "\n",
        "\n",
        "def clip_gradient(optimizer, grad_clip):\n",
        "    \"\"\"\n",
        "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
        "    :param optimizer: optimizer with the gradients to be clipped\n",
        "    :param grad_clip: clip value\n",
        "    \"\"\"\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n",
        "\n",
        "def save_checkpoint(epoch, epochs_since_improvement, model, metric_fc, optimizer, acc, is_best):\n",
        "    print('saving checkpoint ...')\n",
        "    state = {'epoch': epoch,\n",
        "             'epochs_since_improvement': epochs_since_improvement,\n",
        "             'acc': acc,\n",
        "             'model': model,\n",
        "             'metric_fc': metric_fc,\n",
        "             'optimizer': optimizer}\n",
        "    # filename = 'checkpoint_' + str(epoch) + '_' + str(loss) + '.tar'\n",
        "    filename = 'checkpoint.tar'\n",
        "    torch.save(state, filename)\n",
        "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
        "    if is_best:\n",
        "        torch.save(state, 'BEST_checkpoint.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Keeps track of most recent, average, sum, and count of a metric.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, shrink_factor):\n",
        "    \"\"\"\n",
        "    Shrinks learning rate by a specified factor.\n",
        "    :param optimizer: optimizer whose learning rate must be shrunk.\n",
        "    :param shrink_factor: factor in interval (0, 1) to multiply learning rate with.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nDECAYING learning rate.\")\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr'] * shrink_factor\n",
        "    print(\"The new learning rate is %f\\n\" % (optimizer.param_groups[0]['lr'],))\n",
        "\n",
        "\n",
        "def accuracy(scores, targets, k=1):\n",
        "    batch_size = targets.size(0)\n",
        "    _, ind = scores.topk(k, 1, True, True)\n",
        "    correct = ind.eq(targets.view(-1, 1).expand_as(ind))\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / batch_size)\n",
        "\n",
        "\n",
        "def align_face(img_fn, facial5points):\n",
        "    raw = cv.imread(img_fn, True)  # BGR\n",
        "    facial5points = np.reshape(facial5points, (2, 5))\n",
        "\n",
        "    crop_size = (image_h, image_w)\n",
        "\n",
        "    default_square = True\n",
        "    inner_padding_factor = 0.25\n",
        "    outer_padding = (0, 0)\n",
        "    output_size = (image_h, image_w)\n",
        "\n",
        "    # get the reference 5 landmarks position in the crop settings\n",
        "    reference_5pts = get_reference_facial_points(\n",
        "        output_size, inner_padding_factor, outer_padding, default_square)\n",
        "\n",
        "    # dst_img = warp_and_crop_face(raw, facial5points)\n",
        "    dst_img = warp_and_crop_face(raw, facial5points, reference_pts=reference_5pts, crop_size=crop_size)\n",
        "    return dst_img\n",
        "\n",
        "\n",
        "def get_face_attributes(full_path):\n",
        "    try:\n",
        "        img = cv.imread(full_path, cv.IMREAD_COLOR)\n",
        "        bounding_boxes, landmarks = detect_faces(img)\n",
        "\n",
        "        if len(landmarks) > 0:\n",
        "            landmarks = [int(round(x)) for x in landmarks[0]]\n",
        "            return True, landmarks\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        raise\n",
        "    except Exception as err:\n",
        "        print(err)\n",
        "    return False, None\n",
        "\n",
        "\n",
        "def select_significant_face(bboxes):\n",
        "    best_index = -1\n",
        "    best_rank = float('-inf')\n",
        "    for i, b in enumerate(bboxes):\n",
        "        bbox_w, bbox_h = b[2] - b[0], b[3] - b[1]\n",
        "        area = bbox_w * bbox_h\n",
        "        score = b[4]\n",
        "        rank = score * area\n",
        "        if rank > best_rank:\n",
        "            best_rank = rank\n",
        "            best_index = i\n",
        "\n",
        "    return best_index\n",
        "\n",
        "\n",
        "def get_central_face_attributes(full_path):\n",
        "    img = cv.imread(full_path, cv.IMREAD_COLOR)\n",
        "    bboxes, landmarks = detect_faces(img)\n",
        "\n",
        "    if len(landmarks) > 0:\n",
        "        i = select_significant_face(bboxes)\n",
        "        return [bboxes[i]], [landmarks[i]]\n",
        "\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def get_all_face_attributes(full_path):\n",
        "    img = cv.imread(full_path, cv.IMREAD_COLOR)\n",
        "    bounding_boxes, landmarks = detect_faces(img)\n",
        "    return bounding_boxes, landmarks\n",
        "\n",
        "\n",
        "def draw_bboxes(img, bounding_boxes, facial_landmarks=[]):\n",
        "    for b in bounding_boxes:\n",
        "        cv.rectangle(img, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), (255, 255, 255), 1)\n",
        "\n",
        "    for p in facial_landmarks:\n",
        "        for i in range(5):\n",
        "            cv.circle(img, (int(p[i]), int(p[i + 5])), 1, (0, 255, 0), -1)\n",
        "\n",
        "        break  # only first\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Train face network')\n",
        "    # general\n",
        "    parser.add_argument('--pretrained', type=bool, default=False, help='pretrained model')\n",
        "    parser.add_argument('--network', default='r101', help='specify network')\n",
        "    parser.add_argument('--end-epoch', type=int, default=1000, help='training epoch size.')\n",
        "    parser.add_argument('--lr', type=float, default=0.1, help='start learning rate')\n",
        "    parser.add_argument('--lr-step', type=int, default=10, help='period of learning rate decay')\n",
        "    parser.add_argument('--optimizer', default='sgd', help='optimizer')\n",
        "    parser.add_argument('--weight-decay', type=float, default=0.0005, help='weight decay')\n",
        "    parser.add_argument('--mom', type=float, default=0.9, help='momentum')\n",
        "    parser.add_argument('--emb-size', type=int, default=512, help='embedding length')\n",
        "    parser.add_argument('--batch-size', type=int, default=512, help='batch size in each context')\n",
        "    parser.add_argument('--margin-m', type=float, default=0.5, help='angular margin m')\n",
        "    parser.add_argument('--margin-s', type=float, default=64.0, help='feature scale s')\n",
        "    parser.add_argument('--easy-margin', type=bool, default=False, help='easy margin')\n",
        "    parser.add_argument('--focal-loss', type=bool, default=False, help='focal loss')\n",
        "    parser.add_argument('--gamma', type=float, default=2.0, help='focusing parameter gamma')\n",
        "    parser.add_argument('--use-se', type=bool, default=False, help='use SEBlock')\n",
        "    parser.add_argument('--full-log', type=bool, default=False, help='full logging')\n",
        "    parser.add_argument('--checkpoint', type=str, default=None, help='checkpoint')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "def get_logger():\n",
        "    logger = logging.getLogger()\n",
        "    handler = logging.StreamHandler()\n",
        "    formatter = logging.Formatter(\"%(asctime)s %(levelname)s \\t%(message)s\")\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.addHandler(handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "    return logger\n",
        "\n",
        "\n",
        "def ensure_folder(folder):\n",
        "    import os\n",
        "    if not os.path.isdir(folder):\n",
        "        os.mkdir(folder)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-150803cb75f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malign_faces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_reference_facial_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'detector'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERjxPueZSQD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/config.py\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0Q5E8qaST_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/detector.py\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W88TKu8hSG3e",
        "colab_type": "code",
        "outputId": "add8b398-af72-48ff-8a4b-7f918407ddda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/DLDatasets\")\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " align_faces.py     image_aug.ipynb     net.py\n",
            " box_utils1.py\t    _init_.py\t        prior_box.py\n",
            " config1.py\t    insightface         __pycache__\n",
            " config.py\t    insightface1        py_cpu_nms.py\n",
            " data\t\t    InsightFace-v2      retinaface.py\n",
            " data_augment.py    lfw_eval.py         train.py\n",
            " data_gen.ipynb     loader.py\t       'Untitled0 (1).ipynb'\n",
            " data_gen.py\t    models.py\t        visualization_utils.py\n",
            " first_stage.py     msceleb.zip         wider_face.py\n",
            " focal_loss.ipynb   multibox_loss1.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}