{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5MqFwI06e8",
        "colab_type": "code",
        "outputId": "e7b36ded-37eb-4616-8952-bd80f6960e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "#utils.py\n",
        "import argparse\n",
        "import logging\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from align_faces import get_reference_facial_points, warp_and_crop_face\n",
        "from config import image_h, image_w\n",
        "from detector import detect_faces\n",
        "\n",
        "\n",
        "def clip_gradient(optimizer, grad_clip):\n",
        "    \"\"\"\n",
        "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
        "    :param optimizer: optimizer with the gradients to be clipped\n",
        "    :param grad_clip: clip value\n",
        "    \"\"\"\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n",
        "\n",
        "def save_checkpoint(epoch, epochs_since_improvement, model, metric_fc, optimizer, acc, is_best):\n",
        "    print('saving checkpoint ...')\n",
        "    state = {'epoch': epoch,\n",
        "             'epochs_since_improvement': epochs_since_improvement,\n",
        "             'acc': acc,\n",
        "             'model': model,\n",
        "             'metric_fc': metric_fc,\n",
        "             'optimizer': optimizer}\n",
        "    # filename = 'checkpoint_' + str(epoch) + '_' + str(loss) + '.tar'\n",
        "    filename = 'checkpoint.tar'\n",
        "    torch.save(state, filename)\n",
        "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
        "    if is_best:\n",
        "        torch.save(state, 'BEST_checkpoint.tar')\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"\n",
        "    Keeps track of most recent, average, sum, and count of a metric.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, shrink_factor):\n",
        "    \"\"\"\n",
        "    Shrinks learning rate by a specified factor.\n",
        "    :param optimizer: optimizer whose learning rate must be shrunk.\n",
        "    :param shrink_factor: factor in interval (0, 1) to multiply learning rate with.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\nDECAYING learning rate.\")\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = param_group['lr'] * shrink_factor\n",
        "    print(\"The new learning rate is %f\\n\" % (optimizer.param_groups[0]['lr'],))\n",
        "\n",
        "\n",
        "def accuracy(scores, targets, k=1):\n",
        "    batch_size = targets.size(0)\n",
        "    _, ind = scores.topk(k, 1, True, True)\n",
        "    correct = ind.eq(targets.view(-1, 1).expand_as(ind))\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / batch_size)\n",
        "\n",
        "\n",
        "def align_face(img_fn, facial5points):\n",
        "    raw = cv.imread(img_fn, True)  # BGR\n",
        "    facial5points = np.reshape(facial5points, (2, 5))\n",
        "\n",
        "    crop_size = (image_h, image_w)\n",
        "\n",
        "    default_square = True\n",
        "    inner_padding_factor = 0.25\n",
        "    outer_padding = (0, 0)\n",
        "    output_size = (image_h, image_w)\n",
        "\n",
        "    # get the reference 5 landmarks position in the crop settings\n",
        "    reference_5pts = get_reference_facial_points(\n",
        "        output_size, inner_padding_factor, outer_padding, default_square)\n",
        "\n",
        "    # dst_img = warp_and_crop_face(raw, facial5points)\n",
        "    dst_img = warp_and_crop_face(raw, facial5points, reference_pts=reference_5pts, crop_size=crop_size)\n",
        "    return dst_img\n",
        "\n",
        "\n",
        "def get_face_attributes(full_path):\n",
        "    try:\n",
        "        img = cv.imread(full_path, cv.IMREAD_COLOR)\n",
        "        bounding_boxes, landmarks = detect_faces(img)\n",
        "\n",
        "        if len(landmarks) > 0:\n",
        "            landmarks = [int(round(x)) for x in landmarks[0]]\n",
        "            return True, landmarks\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        raise\n",
        "    except Exception as err:\n",
        "        print(err)\n",
        "    return False, None\n",
        "\n",
        "\n",
        "def select_significant_face(bboxes):\n",
        "    best_index = -1\n",
        "    best_rank = float('-inf')\n",
        "    for i, b in enumerate(bboxes):\n",
        "        bbox_w, bbox_h = b[2] - b[0], b[3] - b[1]\n",
        "        area = bbox_w * bbox_h\n",
        "        score = b[4]\n",
        "        rank = score * area\n",
        "        if rank > best_rank:\n",
        "            best_rank = rank\n",
        "            best_index = i\n",
        "\n",
        "    return best_index\n",
        "\n",
        "\n",
        "def get_central_face_attributes(full_path):\n",
        "    img = cv.imread(full_path, cv.IMREAD_COLOR)\n",
        "    bboxes, landmarks = detect_faces(img)\n",
        "\n",
        "    if len(landmarks) > 0:\n",
        "        i = select_significant_face(bboxes)\n",
        "        return [bboxes[i]], [landmarks[i]]\n",
        "\n",
        "    return None, None\n",
        "\n",
        "\n",
        "def get_all_face_attributes(full_path):\n",
        "    img = cv.imread(full_path, cv.IMREAD_COLOR)\n",
        "    bounding_boxes, landmarks = detect_faces(img)\n",
        "    return bounding_boxes, landmarks\n",
        "\n",
        "\n",
        "def draw_bboxes(img, bounding_boxes, facial_landmarks=[]):\n",
        "    for b in bounding_boxes:\n",
        "        cv.rectangle(img, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), (255, 255, 255), 1)\n",
        "\n",
        "    for p in facial_landmarks:\n",
        "        for i in range(5):\n",
        "            cv.circle(img, (int(p[i]), int(p[i + 5])), 1, (0, 255, 0), -1)\n",
        "\n",
        "        break  # only first\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Train face network')\n",
        "    # general\n",
        "    parser.add_argument('--pretrained', type=bool, default=False, help='pretrained model')\n",
        "    parser.add_argument('--network', default='r101', help='specify network')\n",
        "    parser.add_argument('--end-epoch', type=int, default=1000, help='training epoch size.')\n",
        "    parser.add_argument('--lr', type=float, default=0.1, help='start learning rate')\n",
        "    parser.add_argument('--lr-step', type=int, default=10, help='period of learning rate decay')\n",
        "    parser.add_argument('--optimizer', default='sgd', help='optimizer')\n",
        "    parser.add_argument('--weight-decay', type=float, default=0.0005, help='weight decay')\n",
        "    parser.add_argument('--mom', type=float, default=0.9, help='momentum')\n",
        "    parser.add_argument('--emb-size', type=int, default=512, help='embedding length')\n",
        "    parser.add_argument('--batch-size', type=int, default=512, help='batch size in each context')\n",
        "    parser.add_argument('--margin-m', type=float, default=0.5, help='angular margin m')\n",
        "    parser.add_argument('--margin-s', type=float, default=64.0, help='feature scale s')\n",
        "    parser.add_argument('--easy-margin', type=bool, default=False, help='easy margin')\n",
        "    parser.add_argument('--focal-loss', type=bool, default=False, help='focal loss')\n",
        "    parser.add_argument('--gamma', type=float, default=2.0, help='focusing parameter gamma')\n",
        "    parser.add_argument('--use-se', type=bool, default=False, help='use SEBlock')\n",
        "    parser.add_argument('--full-log', type=bool, default=False, help='full logging')\n",
        "    parser.add_argument('--checkpoint', type=str, default=None, help='checkpoint')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "\n",
        "def get_logger():\n",
        "    logger = logging.getLogger()\n",
        "    handler = logging.StreamHandler()\n",
        "    formatter = logging.Formatter(\"%(asctime)s %(levelname)s \\t%(message)s\")\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.addHandler(handler)\n",
        "    logger.setLevel(logging.INFO)\n",
        "    return logger\n",
        "\n",
        "\n",
        "def ensure_folder(folder):\n",
        "    import os\n",
        "    if not os.path.isdir(folder):\n",
        "        os.mkdir(folder)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-150803cb75f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malign_faces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_reference_facial_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarp_and_crop_face\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/DLDatasets/detector.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# device = torch.device('cpu')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/DLDatasets/loader.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetinaFace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg_mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mpretrained_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"state_dict\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpretrained_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m             raise AssertionError(\n\u001b[1;32m    152\u001b[0m                 \"libcudart functions unavailable. It looks like you have a broken build?\")\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:47"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M0kLRN88P7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1981ae99-ba64-4c6c-bb0a-a25f3b3379a9"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/DLDatasets\")\n",
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "align_faces.py\t detector.py\t   lfw_eval.py\t      py_cpu_nms.py\n",
            "box_utils1.py\t first_stage.py    loader.py\t      retinaface.py\n",
            "box_utils.py\t focal_loss.ipynb  models1.ipynb      train.py\n",
            "config1.py\t image_aug.ipynb   models.py\t      utils.py\n",
            "config.py\t _init_.py\t   msceleb.zip\t      visualization_utils.py\n",
            "data\t\t _init.py\t   multibox_loss1.py  wider_face.py\n",
            "data_augment.py  insightface\t   net.py\n",
            "data_gen.ipynb\t insightface1\t   prior_box.py\n",
            "data_gen.py\t InsightFace-v2    __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMTt5IiR8hAJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "756109e2-2450-40af-abb8-e97a2115c26e"
      },
      "source": [
        "!cp \"/content/drive/My Drive/DLDatasets/detector.py\" ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: '/content/drive/My Drive/DLDatasets/detector.py' and './detector.py' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}